#!/usr/bin/env python3
"""
ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ FastAPI Ø¨Ø±Ø§ÛŒ Ù†Ø§Ø·Ù‚ Ø§ÙˆÙ„ØªÛŒÙ…ÛŒØª
Ø¨Ø§ ØªÙ…Ø§Ù… endpointÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
"""

from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse, FileResponse, HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
import logging
import os
import json
import asyncio
from typing import Optional

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Ø§ÛŒØ¬Ø§Ø¯ Ø§Ù¾
app = FastAPI(
    title="Ù†Ø§Ø·Ù‚ Ø§ÙˆÙ„ØªÛŒÙ…ÛŒØª",
    description="Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙØ§Ø±Ø³ÛŒ",
    version="2.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== ENDPOINT Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ ====================

@app.get("/")
async def root():
    """ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ"""
    return FileResponse("public/index.html")

@app.get("/api/")
async def api_root():
    """Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… endpointÙ‡Ø§"""
    return {
        "message": "Ø¨Ù‡ Ù†Ø§Ø·Ù‚ Ø§ÙˆÙ„ØªÛŒÙ…ÛŒØª Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯",
        "version": "2.0.0",
        "endpoints": [
            "/api/",
            "/api/health",
            "/api/chat",
            "/api/test-openai", 
            "/api/status",
            "/api/clear-memory",
            "/api/process",
            "/api/file-info",
            "/api/logs",
            "/api/system-info",
            "/api/docs"
        ],
        "ai_enabled": True
    }

@app.get("/api/health")
async def health_check():
    """Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª"""
    return {
        "status": "healthy",
        "service": "natiq-ultimate-ai",
        "version": "2.0.0",
        "timest
    }

@app.post("/api/chat")
async def chat_endpoint(request: Request):
    """Ù…Ú©Ø§Ù„Ù…Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² OpenAI"""
    try:
        data = await request.json()
        message = data.get("message", "").strip()
        
        if not message:
            raise HTTPException(status_code=400, detail="Ù¾ÛŒØ§Ù… Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯")
        
        logger.info(f"ğŸ’¬ Ú†Øª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: {message[:50]}...")
        
        # Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù…
        responses = {
            "Ø³Ù„Ø§Ù…": "Ø³Ù„Ø§Ù…! ğŸ‘‹ Ø¨Ù‡ Ù†Ø§Ø·Ù‚ Ø§ÙˆÙ„ØªÛŒÙ…ÛŒØª Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯. Ú†Ø·ÙˆØ± Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù… Ú©Ù…Ú© Ú©Ù†Ù…ØŸ",
            "Ø®Ø¯Ø§Ø­Ø§ÙØ¸": "Ø®Ø¯Ø§Ø­Ø§ÙØ¸! Ø§Ù…ÛŒØ¯ÙˆØ§Ø±Ù… Ù…ÙÛŒØ¯ Ø¨ÙˆØ¯Ù‡ Ø¨Ø§Ø´Ù…. ğŸŒŸ",
            "Ú†Ø·ÙˆØ±ÛŒ": "Ù…Ù† Ø®ÙˆØ¨Ù… Ù…Ù…Ù†ÙˆÙ†! ğŸ˜Š Ø´Ù…Ø§ Ú†Ø·ÙˆØ±ÛŒØ¯ØŸ",
            "Ø§Ø³Ù…Øª Ú†ÛŒÙ‡": "Ù…Ù† Ù†Ø§Ø·Ù‚ Ø§ÙˆÙ„ØªÛŒÙ…ÛŒØª Ù‡Ø³ØªÙ…ØŒ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙØ§Ø±Ø³ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡.",
            "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ": "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø´Ø§Ø®Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¹Ù„ÙˆÙ… Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ± Ø§Ø³Øª Ú©Ù‡ Ø¨Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø§Ø´ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…ÛŒâ€ŒÙ¾Ø±Ø¯Ø§Ø²Ø¯. Ø§Ù…Ø±ÙˆØ²Ù‡ Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø§Ø² Ø¬Ù…Ù„Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø¯Ø§Ø±Ø¯.",
            "ØªØ´Ú©Ø±": "Ø®ÙˆØ§Ù‡Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ù…! ğŸ˜Š Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø± Ø®Ø¯Ù…ØªÙ….",
            "Ø²Ù…Ø§Ù†": f"Ø²Ù…Ø§Ù† Ø³Ø±ÙˆØ±: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "ÙˆØ±Ú˜Ù†": f"Ù†Ø§Ø·Ù‚ Ø§ÙˆÙ„ØªÛŒÙ…ÛŒØª Ù†Ø³Ø®Ù‡ 2.0.0 - Ø³ÛŒØ³ØªÙ… AI ÙØ¹Ø§Ù„"
        }
        
        # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù¾Ø§Ø³Ø® Ù…Ù†Ø§Ø³Ø¨
        message_lower = message.lower()
        
        # Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ø®Ø§Øµ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒâ€ŒØ´Ø¯Ù‡
        if "Ø±Ø§Ù…ÛŒÙ† Ø§Ø¬Ù„Ø§Ù„" in message_lower:
            return {
                "success": True,
                "response": "Ø±Ø§Ù…ÛŒÙ† Ø§Ø¬Ù„Ø§Ù„ ÛŒÚ© ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ùˆ Ø¹Ù„Ø§Ù‚Ù‡â€ŒÙ…Ù†Ø¯ Ø¨Ù‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ ÙÙ†Ø§ÙˆØ±ÛŒ Ø§Ø³Øª. Ø§Ùˆ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ Ù†Ø§Ø·Ù‚ Ø§ÙˆÙ„ØªÛŒÙ…ÛŒØª Ø±Ø§ ØªÙˆØ³Ø¹Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯. ğŸ”§",
                "ai_enhanced": True,
                "model": "natiq-ai-knowledge"
            }
        
        # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª OpenAI Ú©Ø±Ø¯Ù‡
        if "openai" in message_lower or "Ø§Ù¾Ù† Ø§ÛŒ" in message_lower or "gpt" in message_lower:
            # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø§Ø³Ø® OpenAI
            openai_responses = [
                "Ù…Ù† Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù…. ğŸ”",
                "Ø³ÛŒØ³ØªÙ… OpenAI ÙØ¹Ø§Ù„ Ø§Ø³Øª Ùˆ Ø¢Ù…Ø§Ø¯Ù‡ Ù¾Ø§Ø³Ø®Ú¯ÙˆÛŒÛŒ Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ø´Ù…Ø§Ø³Øª. ğŸ¤–",
                "Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø§Ù…Ù„ Ø§Ø² Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ OpenAIØŒ Ù„Ø·ÙØ§Ù‹ API Key Ø±Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª Vercel ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.",
                "Ù…Ù† Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù… Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø®ØªÙ„ÙÛŒ Ù¾Ø§Ø³Ø® Ø¯Ù‡Ù…. Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ÛŒØ¯! ğŸ’­"
            ]
            
            import random
            return {
                "success": True,
                "response": random.choice(openai_responses),
                "openai_mode": "simulated",
                "tip": "Ø¨Ø±Ø§ÛŒ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ OpenAI ÙˆØ§Ù‚Ø¹ÛŒØŒ Ú©Ù„ÛŒØ¯ API Ø±Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª Vercel Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯."
            }
        
        # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù¾Ø§Ø³Ø® Ø¯Ø± Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ
        for keyword, resp in responses.items():
            if keyword in message_lower:
                return {
                    "success": True,
                    "response": resp,
                    "keyword_matched": keyword,
                    "ai_model": "natiq-ai-v2"
                }
        
        # Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ
        intelligent_responses = [
            f"Ø³ÙˆØ§Ù„ Ø¬Ø§Ù„Ø¨ÛŒ Ù¾Ø±Ø³ÛŒØ¯ÛŒØ¯: '{message[:30]}...'. Ù…Ù† Ø¯Ø± Ø­Ø§Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù‡Ø³ØªÙ… Ùˆ Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù… Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ø¯Ù‡Ù…. ğŸ“š",
            "Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ø¯. Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø¨Ø¯Ù‡ÛŒØ¯ØŸ",
            "Ù…Ù† ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙØ§Ø±Ø³ÛŒ Ù‡Ø³ØªÙ…. Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª ØªØ®ØµØµÛŒâ€ŒØªØ±ØŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ù… Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ ØªØ®ØµØµÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.",
            "Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³ÙˆØ§Ù„ Ø´Ù…Ø§ Ù‡Ø³ØªÙ…. ğŸ”„"
        ]
        
        import random
        return {
            "success": True,
            "response": random.choice(intelligent_responses),
            "message_length": len(message),
            "ai_model": "natiq-ai-smart",
            "note": "Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ØŒ OpenAI Ø±Ø§ ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯"
        }
        
    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="ÙØ±Ù…Øª JSON Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ú†Øª: {str(e)}")
        return {
            "success": False,
            "error": f"Ø®Ø·Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´: {str(e)}",
            "response": "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
        }

@app.post("/api/openai-test")
async def openai_test_endpoint(request: Request):
    """ØªØ³Øª Ø§ØªØµØ§Ù„ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ù‡ OpenAI"""
    try:
        data = await request.json()
        message = data.get("message", "Ø³Ù„Ø§Ù…")
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú©Ù„ÛŒØ¯ OpenAI
        import os
        openai_key = os.environ.get("OPENAI_API_KEY")
        
        if not openai_key:
            logger.warning("Ú©Ù„ÛŒØ¯ OpenAI ÛŒØ§ÙØª Ù†Ø´Ø¯ - Ø­Ø§Ù„Øª Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ")
            
            # Ù¾Ø§Ø³Ø® Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
            simulated_responses = {
                "Ø³Ù„Ø§Ù…": "Ø³Ù„Ø§Ù…! Ù…Ù† Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø´Ù…Ø§ Ù‡Ø³ØªÙ…. ğŸ”§",
                "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ": "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø­Ø§Ù„ ØªØºÛŒÛŒØ± Ø¯Ù†ÛŒØ§Ø³Øª!",
                "Ø±Ø§Ù…ÛŒÙ† Ø§Ø¬Ù„Ø§Ù„": "ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ - Ø¹Ù„Ø§Ù‚Ù‡â€ŒÙ…Ù†Ø¯ Ø¨Ù‡ AI Ùˆ ÙÙ†Ø§ÙˆØ±ÛŒ.",
                "Ù†Ø§Ø·Ù‚": "Ù†Ø§Ø·Ù‚ Ø§ÙˆÙ„ØªÛŒÙ…ÛŒØª ÛŒÚ© Ù¾Ø±ÙˆÚ˜Ù‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª."
            }
            
            response = "Ù…Ù† ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± AI ÙØ§Ø±Ø³ÛŒ Ù‡Ø³ØªÙ…. Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡â€ŒØªØ±ØŒ Ú©Ù„ÛŒØ¯ OpenAI Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯."
            
            for keyword, resp in simulated_responses.items():
                if keyword in message.lower():
                    response = resp
                    break
            
            return {
                "success": True,
                "response": response,
                "openai_status": "simulated",
                "message": "Ú©Ù„ÛŒØ¯ OpenAI ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù¾Ø§Ø³Ø® Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.",
                "setup_instructions": "Ø¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª VercelØŒ Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ OPENAI_API_KEY Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯."
            }
        
        # Ø§Ú¯Ø± Ú©Ù„ÛŒØ¯ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø§Ø² OpenAI ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
        try:
            # Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù†ØµØ¨ openai package Ø¯Ø§Ø±Ø¯
            # pip install openai
            import openai
            openai.api_key = openai_key
            
            completion = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙØ§Ø±Ø³ÛŒ Ù‡Ø³ØªÛŒØ¯. Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯."},
                    {"role": "user", "content": message}
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            response = completion.choices[0].message.content
            
            return {
                "success": True,
                "response": response,
                "openai_status": "connected",
                "model": "gpt-3.5-turbo",
                "tokens_used": completion.usage.total_tokens
            }
            
        except ImportError:
            logger.error("Ù¾Ú©ÛŒØ¬ openai Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
            return {
                "success": False,
                "error": "Ù¾Ú©ÛŒØ¬ openai Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡",
                "setup_instructions": "Ø¯Ø± requirements.txt Ø®Ø· 'openai' Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯."
            }
            
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª OpenAI: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø§ÛŒ OpenAI: {str(e)}")


@app.get("/api/status")
async def get_status():
    """ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…"""
    import platform
    import sys
    
    return {
        "system": {
            "python_version": sys.version.split()[0],
            "platform": platform.system(),
            "api_version": "2.0.0"
        },
        "ai": {
            "status": "active",
            "language": "ÙØ§Ø±Ø³ÛŒ",
            "features": ["chat", "text_processing", "memory"]
        },
        "endpoints_active": 10,
        "uptime": "running"
    }

@app.post("/api/clear-memory")
async def clear_memory():
    """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡ (Ù†Ù…Ø§ÛŒØ´ÛŒ)"""
    return {
        "success": True,
        "message": "Ø­Ø§ÙØ¸Ù‡ Ù…ÙˆÙ‚Øª Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø´Ø¯",
        "cleared_at": __import__("datetime").datetime.now().isoformat()
    }

# ==================== ENDPOINT Ù‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ (Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ) ====================

@app.post("/api/process")
async def process_text(request: Request):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† (Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Ù†Ø³Ø®Ù‡ Ù‚Ø¯ÛŒÙ…)"""
    try:
        data = await request.json()
        text = data.get("text", "").strip()
        
        if not text:
            raise HTTPException(status_code=400, detail="Ù…ØªÙ† Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯")
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯
        if "Ø³Ù„Ø§Ù…" in text:
            response = f"Ø³Ù„Ø§Ù…! Ù…ØªÙ† Ø´Ù…Ø§: '{text[:50]}...' Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯."
        else:
            response = f"Ù…ØªÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {text[:100]}..." if len(text) > 100 else f"Ù…ØªÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {text}"
        
        return {
            "success": True,
            "original_length": len(text),
            "processed_text": response,
            "message": "Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯",
            "language": "fa"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/file-info")
async def get_file_info(path: str = "requirements.txt"):
    """Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„"""
    try:
        import os
        file_path = f"/var/task/{path}" if path.startswith("/") else f"/var/task/{path}"
        
        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„
        return {
            "success": True,
            "file_path": file_path,
            "file_name": os.path.basename(path),
            "exists": True,
            "size": "1024",
            "type": "text/plain",
            "sample": "Ø§ÛŒÙ† ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„ Ø§Ø³Øª...",
            "message": "Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/logs")
async def get_logs(limit: int = 50):
    """Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…"""
    sample_logs = [
        f"{__import__('datetime').datetime.now().isoformat()} - INFO - API v2.0.0 Ø´Ø±ÙˆØ¹ Ø´Ø¯",
        f"{__import__('datetime').datetime.now().isoformat()} - INFO - Ø³Ø±ÙˆÛŒØ³ AI ÙØ¹Ø§Ù„ Ø´Ø¯",
        f"{__import__('datetime').datetime.now().isoformat()} - INFO - Ø¢Ù…Ø§Ø¯Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§",
        f"{__import__('datetime').datetime.now().isoformat()} - INFO - /api/test-openai endpoint ÙØ¹Ø§Ù„ Ø´Ø¯"
    ]
    
    return {
        "success": True,
        "logs": sample_logs[-limit:],
        "total": len(sample_logs),
        "limit": limit
    }

@app.get("/api/system-info")
async def get_system_info():
    """Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³ÛŒØ³ØªÙ…"""
    import platform
    
    return {
        "system": platform.system(),
        "release": platform.release(),
        "python": platform.python_version(),
        "api": "natiq-ultimate-ai",
        "version": "2.0.0"
    }

# ==================== Ù…Ø³ØªÙ†Ø¯Ø§Øª ====================

@app.get("/api/docs")
async def api_docs():
    """Ù…Ø³ØªÙ†Ø¯Ø§Øª API"""
    docs_html = """
    <!DOCTYPE html>
    <html lang="fa" dir="rtl">
    <head>
        <meta charset="UTF-8">
        <title>Ù†Ø§Ø·Ù‚ Ø§ÙˆÙ„ØªÛŒÙ…ÛŒØª - Ù…Ø³ØªÙ†Ø¯Ø§Øª</title>
        <style>
            body { font-family: 'Vazirmatn', sans-serif; padding: 20px; background: #f5f5f5; }
            .container { max-width: 800px; margin: auto; background: white; padding: 30px; border-radius: 15px; box-shadow: 0 5px 15px rgba(0,0,0,0.1); }
            h1 { color: #333; text-align: center; }
            .endpoint { background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 8px; border-right: 4px solid #007bff; }
            .method { display: inline-block; padding: 5px 10px; border-radius: 4px; color: white; font-weight: bold; margin-left: 10px; }
            .get { background: #28a745; }
            .post { background: #007bff; }
            code { background: #eee; padding: 2px 5px; border-radius: 3px; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ“š Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù†Ø§Ø·Ù‚ Ø§ÙˆÙ„ØªÛŒÙ…ÛŒØª API</h1>
            
            <div class="endpoint">
                <span class="method get">GET</span> <code>/api/</code>
                <p>Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… endpointÙ‡Ø§</p>
            </div>
            
            <div class="endpoint">
                <span class="method get">GET</span> <code>/api/health</code>
                <p>Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ø³ÛŒØ³ØªÙ…</p>
            </div>
            
            <div class="endpoint">
                <span class="method post">POST</span> <code>/api/chat</code>
                <p>Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ</p>
                <small>Ø¨Ø¯Ù†Ù‡: {"message": "Ø³Ù„Ø§Ù…"}</small>
            </div>
            
            <div class="endpoint">
                <span class="method get">GET</span> <code>/api/test-openai</code>
                <p>ØªØ³Øª Ø§ØªØµØ§Ù„ OpenAI</p>
            </div>
            
            <div class="endpoint">
                <span class="method get">GET</span> <code>/api/status</code>
                <p>ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…</p>
            </div>
            
            <div class="endpoint">
                <span class="method post">POST</span> <code>/api/clear-memory</code>
                <p>Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡</p>
            </div>
            
            <h2>ğŸ“ ØªØ³Øª Ø³Ø±ÛŒØ¹</h2>
            <pre><code>curl https://natiq-ultimate.vercel.app/api/test-openai</code></pre>
            
            <pre><code>curl -X POST https://natiq-ultimate.vercel.app/api/chat \\
  -H "Content-Type: application/json" \\
  -d '{"message": "Ø³Ù„Ø§Ù…"}'</code></pre>
        </div>
    </body>
    </html>
    """
    return HTMLResponse(content=docs_html)

# ==================== Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ ====================

@app.exception_handler(404)
async def not_found_handler(request: Request, exc: Exception):
    return JSONResponse(
        status_code=404,
        content={
            "success": False,
            "error": "Ù…Ø³ÛŒØ± ÛŒØ§ÙØª Ù†Ø´Ø¯",
            "path": str(request.url.path),
            "available_endpoints": [
                "/api/",
                "/api/health", 
                "/api/chat",
                "/api/test-openai",
                "/api/status",
                "/api/clear-memory",
                "/api/process",
                "/api/file-info", 
                "/api/logs",
                "/api/system-info",
                "/api/docs"
            ],
            "tip": "Ø§Ø² /api/ Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¯Ù† Ù„ÛŒØ³Øª Ú©Ø§Ù…Ù„ endpointÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯"
        }
    )

@app.exception_handler(500)
async def internal_error_handler(request: Request, exc: Exception):
    logger.error(f"Ø®Ø·Ø§ÛŒ 500: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "error": "Ø®Ø·Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø³Ø±ÙˆØ±",
            "message": "Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯"
        }
    )

# Middleware Ø¨Ø±Ø§ÛŒ Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ
@app.middleware("http")
async def log_middleware(request: Request, call_next):
    import time
    start = time.time()
    
    response = await call_next(request)
    
    duration = time.time() - start
    logger.info(f"{request.method} {request.url.path} - {response.status_code} - {duration:.3f}s")
    
    return response

# Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø­Ù„ÛŒ
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
