#!/usr/bin/env python3
"""
Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø®Ø±ÙˆØ¬ÛŒâ€ŒØ¯Ù‡ÛŒ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®ÙˆØ¯Ú©Ø§Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:
1. Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù¾ÙˆØ´Ù‡ Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ø®ÙˆØ¯Ú©Ø§Ø±
2. Ø®ÙˆØ§Ù†Ø¯Ù†/Ù†ÙˆØ´ØªÙ† ÙØ§ÛŒÙ„ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² encoding
3. Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
4. Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ Ø¨Ø§ try-except
"""

import os
import sys
import logging
from pathlib import Path
from datetime import datetime
from typing import Union, Optional, List, Dict, Any
import json
import yaml

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('file_processor.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class FileProcessor:
    """Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª ÙØ§ÛŒÙ„ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø®ÙˆØ¯Ú©Ø§Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§"""
    
    def __init__(self, base_dir: str = "."):
        self.base_dir = Path(base_dir).resolve()
        self.created_dirs = []
        
    def ensure_directory(self, file_path: Union[str, Path]) -> Path:
        """
        Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„
        """
        path = Path(file_path)
        
        # Ø§Ú¯Ø± Ù…Ø³ÛŒØ± Ù…Ø·Ù„Ù‚ Ù†ÛŒØ³ØªØŒ Ù†Ø³Ø¨Øª Ø¨Ù‡ base_dir Ø¨Ø³Ø§Ø²
        if not path.is_absolute():
            path = self.base_dir / path
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù„Ø¯ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ù†Ø¯
        parent_dir = path.parent
        if not parent_dir.exists():
            parent_dir.mkdir(parents=True, exist_ok=True)
            self.created_dirs.append(str(parent_dir))
            logger.info(f"ğŸ“ Ù¾ÙˆØ´Ù‡ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {parent_dir}")
        
        return path
    
    def read_file(self, file_path: str, encoding: str = 'utf-8') -> str:
        """
        Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
        """
        try:
            path = self.ensure_directory(file_path)
            
            if not path.exists():
                logger.warning(f"âš ï¸ ÙØ§ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯: {path}")
                return ""
            
            with open(path, 'r', encoding=encoding) as f:
                content = f.read()
            
            logger.info(f"âœ… ÙØ§ÛŒÙ„ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯: {path} ({len(content)} Ú©Ø§Ø±Ø§Ú©ØªØ±)")
            return content
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ {file_path}: {str(e)}")
            raise
    
    def write_file(self, file_path: str, content: str, 
                   encoding: str = 'utf-8', mode: str = 'w') -> bool:
        """
        Ù†ÙˆØ´ØªÙ† Ø¯Ø± ÙØ§ÛŒÙ„ Ø¨Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ø®ÙˆØ¯Ú©Ø§Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
        """
        try:
            path = self.ensure_directory(file_path)
            
            with open(path, mode, encoding=encoding) as f:
                f.write(content)
            
            logger.info(f"âœ… ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {path} ({len(content)} Ú©Ø§Ø±Ø§Ú©ØªØ±)")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù†ÙˆØ´ØªÙ† ÙØ§ÛŒÙ„ {file_path}: {str(e)}")
            return False
    
    def cat_with_info(self, file_path: str, show_stats: bool = True) -> str:
        """
        Ù†Ù…Ø§ÛŒØ´ Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢Ù…Ø§Ø±ÛŒ (Ø´Ø¨ÛŒÙ‡ cat Ù¾ÛŒØ´Ø±ÙØªÙ‡)
        """
        content = self.read_file(file_path)
        path = Path(file_path)
        
        if not content:
            return "ÙØ§ÛŒÙ„ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª ÛŒØ§ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯"
        
        output = []
        
        if show_stats:
            output.append(f"ğŸ“Š Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„: {path.name}")
            output.append(f"ğŸ“ Ù…Ø³ÛŒØ± Ú©Ø§Ù…Ù„: {path.absolute()}")
            output.append(f"ğŸ“ Ø­Ø¬Ù… ÙØ§ÛŒÙ„: {len(content)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
            output.append(f"ğŸ“ ØªØ¹Ø¯Ø§Ø¯ Ø®Ø·ÙˆØ·: {len(content.splitlines())}")
            output.append(f"ğŸ•’ Ø²Ù…Ø§Ù† Ø¨Ø±Ø±Ø³ÛŒ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            output.append("-" * 50)
        
        output.append(content)
        
        if show_stats:
            output.append("-" * 50)
            output.append(f"âœ… Ù†Ù…Ø§ÛŒØ´ ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
        
        return "\n".join(output)
    
    def process_multiple_files(self, file_paths: List[str], 
                               operation: str = 'read') -> Dict[str, Any]:
        """
        Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú†Ù†Ø¯ÛŒÙ† ÙØ§ÛŒÙ„ Ø¨Ù‡ ØµÙˆØ±Øª Ù‡Ù…Ø²Ù…Ø§Ù†
        """
        results = {
            'success': [],
            'failed': [],
            'stats': {
                'total': len(file_paths),
                'processed': 0,
                'created_dirs': self.created_dirs
            }
        }
        
        for file_path in file_paths:
            try:
                if operation == 'read':
                    content = self.read_file(file_path)
                    results['success'].append({
                        'file': file_path,
                        'content_preview': content[:100] + '...' if len(content) > 100 else content
                    })
                elif operation == 'cat':
                    content = self.cat_with_info(file_path)
                    results['success'].append({
                        'file': file_path,
                        'displayed': True
                    })
                
                results['stats']['processed'] += 1
                
            except Exception as e:
                results['failed'].append({
                    'file': file_path,
                    'error': str(e)
                })
        
        return results
    
    def get_directory_tree(self, dir_path: str = ".", max_depth: int = 3) -> str:
        """
        ØªÙˆÙ„ÛŒØ¯ Ø¯Ø±Ø®Øª Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ùˆ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
        """
        def build_tree(path: Path, prefix: str = "", depth: int = 0) -> List[str]:
            if depth > max_depth:
                return []
            
            lines = []
            try:
                contents = sorted(path.iterdir())
                for i, item in enumerate(contents):
                    is_last = (i == len(contents) - 1)
                    
                    if item.is_dir():
                        lines.append(f"{prefix}{'â””â”€â”€ ' if is_last else 'â”œâ”€â”€ '}ğŸ“ {item.name}/")
                        extension = "    " if is_last else "â”‚   "
                        lines.extend(build_tree(item, prefix + extension, depth + 1))
                    else:
                        lines.append(f"{prefix}{'â””â”€â”€ ' if is_last else 'â”œâ”€â”€ '}ğŸ“„ {item.name}")
            except PermissionError:
                lines.append(f"{prefix}â””â”€â”€ ğŸ”’ Ø¯Ø³ØªØ±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯")
            
            return lines
        
        root = Path(dir_path).resolve()
        tree_lines = [f"ğŸŒ³ Ø³Ø§Ø®ØªØ§Ø± Ù¾ÙˆØ´Ù‡: {root}"]
        tree_lines.extend(build_tree(root))
        return "\n".join(tree_lines)


# ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø³Ø±ÛŒØ¹
def cat(file_path: str, create_dirs: bool = True, show_info: bool = True) -> str:
    """
    ØªØ§Ø¨Ø¹ Ø³Ø±ÛŒØ¹ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ÙØ§ÛŒÙ„ (Ø´Ø¨ÛŒÙ‡ Ø¯Ø³ØªÙˆØ± cat Ù„ÛŒÙ†ÙˆÚ©Ø³)
    
    Args:
        file_path: Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„
        create_dirs: Ø§ÛŒØ¬Ø§Ø¯ Ø®ÙˆØ¯Ú©Ø§Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ù†Ø¯
        show_info: Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¶Ø§ÙÛŒ
    
    Returns:
        Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„ Ø¨Ù‡ ØµÙˆØ±Øª Ø±Ø´ØªÙ‡
    """
    processor = FileProcessor()
    
    if create_dirs:
        processor.ensure_directory(file_path)
    
    if show_info:
        return processor.cat_with_info(file_path)
    else:
        return processor.read_file(file_path)


def save_json(data: Any, file_path: str, create_dirs: bool = True) -> bool:
    """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Ù‚Ø§Ù„Ø¨ JSON"""
    processor = FileProcessor()
    
    if create_dirs:
        processor.ensure_directory(file_path)
    
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        logger.info(f"âœ… JSON Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {file_path}")
        return True
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ JSON: {e}")
        return False


def load_json(file_path: str) -> Optional[Dict]:
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ø² JSON"""
    processor = FileProcessor()
    content = processor.read_file(file_path)
    
    if content:
        try:
            return json.loads(content)
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† JSON: {e}")
    return None


# Ù…Ø«Ø§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡
if __name__ == "__main__":
    print("ğŸ”§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù…Ø¯ÛŒØ±ÛŒØª ÙØ§ÛŒÙ„")
    print("=" * 50)
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡
    fp = FileProcessor()
    
    # Ù…Ø«Ø§Ù„ 1: Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡ Ùˆ Ù†Ù…Ø§ÛŒØ´ ÙØ§ÛŒÙ„
    test_file = "logs/app/test_log.txt"
    content = "Ø§ÛŒÙ† ÛŒÚ© ÙØ§ÛŒÙ„ ØªØ³Øª Ø§Ø³Øª.\nØªØ§Ø±ÛŒØ® Ø§ÛŒØ¬Ø§Ø¯: " + datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    if fp.write_file(test_file, content):
        print(f"\nğŸ“ ÙØ§ÛŒÙ„ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {test_file}")
        
        # Ù†Ù…Ø§ÛŒØ´ Ø¨Ø§ cat Ù¾ÛŒØ´Ø±ÙØªÙ‡
        print("\n" + fp.cat_with_info(test_file))
    
    # Ù…Ø«Ø§Ù„ 2: Ù†Ù…Ø§ÛŒØ´ Ø³Ø§Ø®ØªØ§Ø± Ù¾ÙˆØ´Ù‡
    print("\n" + fp.get_directory_tree(".", max_depth=2))
    
    # Ù…Ø«Ø§Ù„ 3: Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú†Ù†Ø¯ ÙØ§ÛŒÙ„
    files_to_process = [
        "data/docs/file1.txt",
        "data/docs/file2.txt",
        "config/settings.json"
    ]
    
    # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡
    for i, file in enumerate(files_to_process):
        fp.write_file(file, f"Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„ Ø¢Ø²Ù…Ø§ÛŒØ´ÛŒ Ø´Ù…Ø§Ø±Ù‡ {i+1}\n" * 3)
    
    # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ù…Ø²Ù…Ø§Ù†
    results = fp.process_multiple_files(files_to_process, operation='cat')
    print(f"\nğŸ“Š Ù†ØªØ§ÛŒØ¬ Ù¾Ø±Ø¯Ø§Ø²Ø´:")
    print(f"   Ù…ÙˆÙÙ‚: {len(results['success'])}")
    print(f"   Ù†Ø§Ù…ÙˆÙÙ‚: {len(results['failed'])}")
    print(f"   Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù‡: {len(results['stats']['created_dirs'])}")
