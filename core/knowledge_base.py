"""
Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ natiq-ultimate
Ø´Ø§Ù…Ù„ Ù…ÙØ§Ù‡ÛŒÙ… Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒØŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†ØŒ Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ Ùˆ ...
"""
import json
import random
from datetime import datetime

class KnowledgeGraph:
    """Ú¯Ø±Ø§Ù Ø¯Ø§Ù†Ø´ Ø¨Ø§ Ù…ÙØ§Ù‡ÛŒÙ… Ùˆ Ø±ÙˆØ§Ø¨Ø·"""
    
    def __init__(self):
        self.graph = self._initialize_knowledge()
        self.cache = {}
        print(f"ğŸ“š Knowledge graph initialized with {len(self.graph)} concepts")
    
    def _initialize_knowledge(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ Ø§ÙˆÙ„ÛŒÙ‡"""
        return {
            "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ": {
                "definition": "Ø´Ø§Ø®Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¹Ù„ÙˆÙ… Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ± Ú©Ù‡ Ø¨Ù‡ Ø³Ø§Ø®Øª Ù…Ø§Ø´ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…ÛŒâ€ŒÙ¾Ø±Ø¯Ø§Ø²Ø¯",
                "category": "fundamental",
                "importance": "very_high",
                "examples": ["ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†", "Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ", "Ø¨ÛŒÙ†Ø§ÛŒÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±", "Ø±Ø¨Ø§ØªÛŒÚ©"],
                "relations": ["ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ_Ù…Ø§Ø´ÛŒÙ†", "Ø´Ø¨Ú©Ù‡_Ø¹ØµØ¨ÛŒ", "Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…"],
                "sources": ["wikipedia", "academic_papers"],
                "last_updated": datetime.now().isoformat()
            },
            "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†": {
                "definition": "ØªÙˆØ§Ù†Ø§ÛŒÛŒ Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡ Ø¨Ø¯ÙˆÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ ØµØ±ÛŒØ­",
                "category": "subfield",
                "importance": "high",
                "examples": ["Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ", "Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ…", "Ù…Ø§Ø´ÛŒÙ† Ø¨Ø±Ø¯Ø§Ø± Ù¾Ø´ØªÛŒØ¨Ø§Ù†", "Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ"],
                "relations": ["Ù‡ÙˆØ´_Ù…ØµÙ†ÙˆØ¹ÛŒ", "Ø¯Ø§Ø¯Ù‡_Ú©Ø§ÙˆÛŒ", "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ"],
                "applications": ["ØªØ´Ø®ÛŒØµ ØªØµÙˆÛŒØ±", "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª", "ØªØ´Ø®ÛŒØµ ØªÙ‚Ù„Ø¨", "Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…Ø­ØµÙˆÙ„"],
                "sources": ["wikipedia", "research_papers"],
                "last_updated": datetime.now().isoformat()
            },
            "Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ": {
                "definition": "Ù…Ø¯Ù„ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ø§Ù„Ù‡Ø§Ù… Ú¯Ø±ÙØªÙ‡ Ø§Ø² Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ Ù…ØºØ²",
                "category": "algorithm",
                "importance": "high",
                "examples": ["Ù¾Ø±Ø³Ù¾ØªØ±ÙˆÙ†", "Ø´Ø¨Ú©Ù‡ Ú©Ø§Ù†ÙˆÙ„ÙˆØ´Ù†", "Ø´Ø¨Ú©Ù‡ Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ", "Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ Ø¹Ù…ÛŒÙ‚"],
                "layers": ["Ù„Ø§ÛŒÙ‡ ÙˆØ±ÙˆØ¯ÛŒ", "Ù„Ø§ÛŒÙ‡ Ù¾Ù†Ù‡Ø§Ù†", "Ù„Ø§ÛŒÙ‡ Ø®Ø±ÙˆØ¬ÛŒ"],
                "relations": ["ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ_Ø¹Ù…ÛŒÙ‚", "Ù¾Ø±Ø¯Ø§Ø²Ø´_ØªØµÙˆÛŒØ±", "Ù¾Ø±Ø¯Ø§Ø²Ø´_Ø²Ø¨Ø§Ù†"],
                "sources": ["academic_papers", "technical_docs"],
                "last_updated": datetime.now().isoformat()
            },
            "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¹Ù…ÛŒÙ‚": {
                "definition": "Ø²ÛŒØ±Ø´Ø§Ø®Ù‡â€ŒØ§ÛŒ Ø§Ø² ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ú©Ù‡ Ø§Ø² Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹ØµØ¨ÛŒ Ø¨Ø§ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù…ØªØ¹Ø¯Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯",
                "category": "advanced",
                "importance": "high",
                "examples": ["Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ Ú©Ø§Ù†ÙˆÙ„ÙˆØ´Ù†", "Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ", "Ù…Ø¨Ø¯Ù„â€ŒÙ‡Ø§"],
                "applications": ["ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø±", "ØªØ±Ø¬Ù…Ù‡ Ù…Ø§Ø´ÛŒÙ†ÛŒ", "ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ†", "ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ±"],
                "relations": ["Ø´Ø¨Ú©Ù‡_Ø¹ØµØ¨ÛŒ", "Ù¾Ø±Ø¯Ø§Ø²Ø´_Ø²Ø¨Ø§Ù†_Ø·Ø¨ÛŒØ¹ÛŒ", "Ø¨ÛŒÙ†Ø§ÛŒÛŒ_Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±"],
                "sources": ["research_papers", "conference_proceedings"],
                "last_updated": datetime.now().isoformat()
            },
            "Ù¾Ø§ÛŒØªÙˆÙ†": {
                "definition": "Ø²Ø¨Ø§Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ø³Ø·Ø­ Ø¨Ø§Ù„Ø§ØŒ Ù…ÙØ³Ø±ÛŒ Ùˆ Ù‡Ù…Ù‡â€ŒÙ…Ù†Ø¸ÙˆØ±Ù‡",
                "category": "tool",
                "importance": "very_high",
                "examples": ["ØªÙ†Ø³ÙˆØ±ÙÙ„Ùˆ", "Ù¾Ø§ÛŒØªÙˆØ±Ú†", "scikit-learn", "numpy", "pandas"],
                "ai_libraries": ["tensorflow", "pytorch", "keras", "scikit-learn", "nltk"],
                "relations": ["Ù‡ÙˆØ´_Ù…ØµÙ†ÙˆØ¹ÛŒ", "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ_Ù…Ø§Ø´ÛŒÙ†", "Ø¯Ø§Ø¯Ù‡_Ú©Ø§ÙˆÛŒ"],
                "sources": ["official_docs", "community"],
                "last_updated": datetime.now().isoformat()
            },
            "Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙˆÛŒ": {
                "definition": "ÙØ±Ø¢ÛŒÙ†Ø¯ Ú©Ø´Ù Ø§Ù„Ú¯ÙˆÙ‡Ø§ Ùˆ Ø¯Ø§Ù†Ø´ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯",
                "category": "process",
                "importance": "high",
                "steps": ["Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡", "ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡", "Ú©Ø§ÙˆØ´ Ø¯Ø§Ø¯Ù‡", "Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø§Ù„Ú¯Ùˆ"],
                "techniques": ["Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ", "Ù‚Ø§Ù†ÙˆÙ†â€ŒÛŒØ§Ø¨ÛŒ", "Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ", "Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†"],
                "relations": ["ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ_Ù…Ø§Ø´ÛŒÙ†", "ØªØ­Ù„ÛŒÙ„_Ø¯Ø§Ø¯Ù‡", "Ù‡ÙˆØ´_ØªØ¬Ø§Ø±ÛŒ"],
                "sources": ["academic_books", "technical_guides"],
                "last_updated": datetime.now().isoformat()
            },
            "Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…": {
                "definition": "Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø­Ù„Ù‡ Ø¨Ù‡ Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø±Ø§ÛŒ Ø­Ù„ ÛŒÚ© Ù…Ø³Ø¦Ù„Ù‡",
                "category": "fundamental",
                "importance": "high",
                "types": ["ØªØ±ØªÛŒØ¨ÛŒ", "Ø¨Ø§Ø²Ú¯Ø´ØªÛŒ", "Ø­Ø±ÛŒØµØ§Ù†Ù‡", "ØªÙ‚Ø³ÛŒÙ… Ùˆ ØºÙ„Ø¨Ù‡", "Ù¾ÙˆÛŒØ§"],
                "examples": ["Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±ÛŒØ¹", "Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¯ÙˆØ¯ÙˆÛŒÛŒ", "Ø¯Ø§ÛŒØ¬Ø³ØªØ±Ø§", "Ø¯Ø±Ø®Øª Ù¾ÙˆØ´Ø§"],
                "relations": ["Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ", "Ø³Ø§Ø®ØªÙ…Ø§Ù†_Ø¯Ø§Ø¯Ù‡", "Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ_Ø²Ù…Ø§Ù†ÛŒ"],
                "sources": ["computer_science_textbooks"],
                "last_updated": datetime.now().isoformat()
            },
            "Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ": {
                "definition": "Ø²Ù…ÛŒÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ú©Ù‡ Ø¨Ù‡ ØªØ¹Ø§Ù…Ù„ Ø¨ÛŒÙ† Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ± Ùˆ Ø²Ø¨Ø§Ù† Ø§Ù†Ø³Ø§Ù† Ù…ÛŒâ€ŒÙ¾Ø±Ø¯Ø§Ø²Ø¯",
                "category": "application",
                "importance": "high",
                "tasks": ["ØªØ¬Ø²ÛŒÙ‡â€ŒÚ¯Ø± Ù†Ø­ÙˆÛŒ", "ØªØ´Ø®ÛŒØµ Ù…ÙˆØ¬ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§", "ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª", "ØªØ±Ø¬Ù…Ù‡ Ù…Ø§Ø´ÛŒÙ†ÛŒ"],
                "models": ["BERT", "GPT", "Transformer", "LSTM"],
                "relations": ["Ù‡ÙˆØ´_Ù…ØµÙ†ÙˆØ¹ÛŒ", "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ_Ù…Ø§Ø´ÛŒÙ†", "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ_Ø¹Ù…ÛŒÙ‚"],
                "sources": ["research_papers", "nlp_books"],
                "last_updated": datetime.now().isoformat()
            },
            "Ø¨ÛŒÙ†Ø§ÛŒÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±": {
                "definition": "Ø²Ù…ÛŒÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ú©Ù‡ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±Ù‡Ø§ Ø±Ø§ Ù‚Ø§Ø¯Ø± Ø¨Ù‡ Ø¯Ø±Ú© Ùˆ ØªÙØ³ÛŒØ± Ø¯Ù†ÛŒØ§ÛŒ Ø¨ØµØ±ÛŒ Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯",
                "category": "application",
                "importance": "high",
                "tasks": ["ØªØ´Ø®ÛŒØµ Ø§Ø´ÛŒØ§", "Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ ØªØµÙˆÛŒØ±", "Ø¨Ø®Ø´â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ", "ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡"],
                "models": ["CNN", "YOLO", "ResNet", "Vision Transformer"],
                "relations": ["ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ_Ø¹Ù…ÛŒÙ‚", "Ø´Ø¨Ú©Ù‡_Ø¹ØµØ¨ÛŒ", "Ù¾Ø±Ø¯Ø§Ø²Ø´_ØªØµÙˆÛŒØ±"],
                "sources": ["computer_vision_papers", "conferences"],
                "last_updated": datetime.now().isoformat()
            },
            "Ø±Ø¨Ø§ØªÛŒÚ©": {
                "definition": "Ø´Ø§Ø®Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ùˆ Ø¹Ù„ÙˆÙ… Ú©Ù‡ Ø¨Ù‡ Ø·Ø±Ø§Ø­ÛŒØŒ Ø³Ø§Ø®Øª Ùˆ Ø¨Ù‡Ø±Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ Ø§Ø² Ø±Ø¨Ø§Øªâ€ŒÙ‡Ø§ Ù…ÛŒâ€ŒÙ¾Ø±Ø¯Ø§Ø²Ø¯",
                "category": "application",
                "importance": "medium",
                "components": ["Ø­Ø³Ú¯Ø±Ù‡Ø§", "Ø¹Ù…Ù„Ú¯Ø±Ù‡Ø§", "Ú©Ù†ØªØ±Ù„â€ŒÚ¯Ø±", "Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø±"],
                "types": ["ØµÙ†Ø¹ØªÛŒ", "Ø®Ø¯Ù…Ø§ØªÛŒ", "Ù¾Ø²Ø´Ú©ÛŒ", "Ù†Ø¸Ø§Ù…ÛŒ"],
                "relations": ["Ù‡ÙˆØ´_Ù…ØµÙ†ÙˆØ¹ÛŒ", "Ú©Ù†ØªØ±Ù„_Ø®ÙˆØ¯Ú©Ø§Ø±", "Ù…Ú©Ø§ØªØ±ÙˆÙ†ÛŒÚ©"],
                "sources": ["robotics_journals", "engineering_books"],
                "last_updated": datetime.now().isoformat()
            }
        }
    
    def search(self, concept):
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…ÙÙ‡ÙˆÙ… Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´"""
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…ÙÙ‡ÙˆÙ…
        normalized = concept.replace(" ", "_")
        
        # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…
        if normalized in self.graph:
            return {
                "found": True,
                "concept": concept,
                "data": self.graph[normalized],
                "source": "knowledge_graph",
                "confidence": 0.95
            }
        
        # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø´Ø§Ø¨Ù‡
        similar = []
        for known_concept in self.graph:
            if concept.lower() in known_concept.lower() or known_concept.lower() in concept.lower():
                similar.append(known_concept)
        
        if similar:
            return {
                "found": True,
                "concept": similar[0],
                "data": self.graph[similar[0]],
                "similar_found": similar,
                "source": "similarity_match",
                "confidence": 0.7
            }
        
        # Ø¬Ø³ØªØ¬ÙˆÛŒ Ú©Ù„Ù…Ù‡â€ŒØ§ÛŒ
        words = concept.split()
        for word in words:
            if len(word) > 2:  # ÙÙ‚Ø· Ú©Ù„Ù…Ø§Øª Ù…Ø¹Ù†ÛŒâ€ŒØ¯Ø§Ø±
                for known_concept in self.graph:
                    if word.lower() in known_concept.lower():
                        return {
                            "found": True,
                            "concept": known_concept,
                            "data": self.graph[known_concept],
                            "matched_word": word,
                            "source": "word_match",
                            "confidence": 0.6
                        }
        
        return {
            "found": False,
            "concept": concept,
            "message": "Ù…ÙÙ‡ÙˆÙ… Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯",
            "suggestions": list(self.graph.keys())[:3],
            "confidence": 0.0
        }
    
    def get_related(self, concept, max_results=5):
        """Ø¯Ø±ÛŒØ§ÙØª Ù…ÙØ§Ù‡ÛŒÙ… Ù…Ø±ØªØ¨Ø·"""
        if concept not in self.graph:
            return []
        
        related = []
        data = self.graph[concept]
        
        # Ø±ÙˆØ§Ø¨Ø· Ù…Ø³ØªÙ‚ÛŒÙ…
        if 'relations' in data:
            for rel in data['relations']:
                if rel in self.graph:
                    related.append(rel)
        
        # Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹Ú©ÙˆØ³ (Ú†Ù‡ Ù…ÙØ§Ù‡ÛŒÙ…ÛŒ Ø¨Ù‡ Ø§ÛŒÙ† Ù…ÙÙ‡ÙˆÙ… Ø§Ø´Ø§Ø±Ù‡ Ø¯Ø§Ø±Ù†Ø¯)
        for other_concept, other_data in self.graph.items():
            if 'relations' in other_data and concept in other_data['relations']:
                related.append(other_concept)
        
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ù†ØªØ§ÛŒØ¬
        related = list(dict.fromkeys(related))
        return related[:max_results]
    
    def get_categories(self):
        """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯"""
        categories = {}
        for concept, data in self.graph.items():
            category = data.get('category', 'unknown')
            if category not in categories:
                categories[category] = []
            categories[category].append(concept)
        
        return categories
    
    def add_concept(self, concept, data):
        """Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙÙ‡ÙˆÙ… Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´"""
        normalized = concept.replace(" ", "_")
        if normalized not in self.graph:
            data['last_updated'] = datetime.now().isoformat()
            data['added_by'] = "user_interaction"
            self.graph[normalized] = data
            return True
        return False
    
    def export(self):
        """Ø®Ø±ÙˆØ¬ÛŒ Ú©Ù„ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´"""
        return {
            "total_concepts": len(self.graph),
            "concepts": list(self.graph.keys()),
            "categories": self.get_categories(),
            "timestamp": datetime.now().isoformat(),
            "version": "1.0.0"
        }
